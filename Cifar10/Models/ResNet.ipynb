{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n",
      "cuda:0\n",
      "Epoch: 1/15 \t Time: 01:24:21.374205 \t Loss: 0.39334962432533505 \t Accuracy: 0.9210000000000003\n",
      "Epoch: 2/15 \t Time: 01:26:01.786989 \t Loss: 0.20061147493803874 \t Accuracy: 0.9390000000000001\n",
      "Epoch: 3/15 \t Time: 01:27:40.370627 \t Loss: 0.14735993371370715 \t Accuracy: 0.9420000000000001\n",
      "Epoch: 4/15 \t Time: 01:29:20.637380 \t Loss: 0.11121415296681225 \t Accuracy: 0.966\n",
      "Epoch: 5/15 \t Time: 01:30:59.424599 \t Loss: 0.08254262488353416 \t Accuracy: 0.9610000000000001\n",
      "Epoch: 6/15 \t Time: 01:32:39.890447 \t Loss: 0.06792509473658574 \t Accuracy: 0.9789999999999999\n",
      "Epoch: 7/15 \t Time: 01:34:21.268450 \t Loss: 0.05823983196039917 \t Accuracy: 0.9770000000000002\n",
      "Epoch: 8/15 \t Time: 01:36:02.793843 \t Loss: 0.05274443494292209 \t Accuracy: 0.981\n",
      "Epoch: 9/15 \t Time: 01:37:44.304546 \t Loss: 0.03879450106025543 \t Accuracy: 0.987\n",
      "Epoch: 10/15 \t Time: 01:39:22.546887 \t Loss: 0.037051780492003306 \t Accuracy: 0.9880000000000001\n",
      "Epoch: 11/15 \t Time: 01:41:04.223595 \t Loss: 0.03652668577960212 \t Accuracy: 0.9890000000000001\n",
      "Epoch: 12/15 \t Time: 01:42:46.946256 \t Loss: 0.02819013034226009 \t Accuracy: 0.9930000000000001\n",
      "Epoch: 13/15 \t Time: 01:44:26.862647 \t Loss: 0.027479869159608643 \t Accuracy: 0.9890000000000001\n",
      "Epoch: 14/15 \t Time: 01:46:07.689258 \t Loss: 0.02586785962513768 \t Accuracy: 0.9930000000000001\n",
      "Epoch: 15/15 \t Time: 01:47:52.386865 \t Loss: 0.02152333253736706 \t Accuracy: 0.9890000000000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "from torchvision.models import resnet18\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import datetime\n",
    "from torch.nn import init, Linear, ReLU, Softmax\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "image_size = (224,224)\n",
    "transform=transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "train_data=dset.CIFAR10(root='./Dataset',train=True,transform=transform,download=False)\n",
    "test_data=dset.CIFAR10(root='./Dataset',train=False,transform=transform,download=False)\n",
    "train_loader=torch.utils.data.DataLoader(train_data,batch_size=20,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(test_data,batch_size=20,shuffle=True)\n",
    "train_len=len(train_data)\n",
    "test_len=len(test_data)\n",
    "print(train_len,test_len)\n",
    "\n",
    "rs18=resnet18(pretrained=True, progress = True) #这里采用resnet18模型\n",
    "\n",
    "#adjust resnet50 to my dataset\n",
    "class r18(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(r18,self).__init__()\n",
    "        self.rn18 = model\n",
    "        self.fl1 = nn.Linear(1000, 256)\n",
    "        self.fl2 = nn.Linear(256,10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.rn18(X)\n",
    "        X = F.relu(self.fl1(X))\n",
    "        X = F.dropout(X, p=0.25)\n",
    "        X = self.fl2(X)\n",
    "        return X\n",
    "def get_num_correct(out, labels):  #求准确率\n",
    "    return out.argmax(dim=1).eq(labels).sum().item()\n",
    "model = r18(rs18)\n",
    "criterion = nn.CrossEntropyLoss(reduction = \"mean\")\n",
    "optim = torch.optim.SGD(model.parameters(),lr=0.01)\n",
    "\n",
    "#put on cuda if possible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "nb_epochs = 15\n",
    "accuracy = []\n",
    "eps = 0.01\n",
    "eps_iter = 0.001\n",
    "steps = 20\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        model.eval()\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        prediction = model(images).to(torch.float32)\n",
    "        loss = criterion(prediction, labels.to(torch.long)) \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        #calculate accuracy\n",
    "        corrects = 0\n",
    "        pred = torch.argmax(prediction, dim = 1)\n",
    "        \n",
    "        for i, p,l in zip(range(64), pred, labels):\n",
    "            corrects += (p == l)\n",
    "        accuracy.append(int(corrects)/len(pred))\n",
    "    \n",
    "    print(\"Epoch: {j}/{total_epochs} \\t Time: {time} \\t Loss: {Loss} \\t Accuracy: {acc}\".format(j = epoch+1,Loss = running_loss/len(train_loader),total_epochs = nb_epochs,time = datetime.datetime.now().time(), acc=np.mean(accuracy[-50:])))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model for our test notebook    \n",
    "PATH = './cifar10_resnet18.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9504\n"
     ]
    }
   ],
   "source": [
    "model = r18(rs18)\n",
    "model.load_state_dict(torch.load('./cifar10_resnet18.pth'))\n",
    "correct_test = 0\n",
    "model.cuda(0)\n",
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        test_features, test_labels = data\n",
    "        outputs = model(test_features.cuda(0))\n",
    "        _,pred_idxs = torch.topk(outputs, 1)\n",
    "        correct_test += torch.eq(test_labels.cuda(0), pred_idxs.squeeze()).sum().item()\n",
    "print(correct_test/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n",
      "cuda:0\n",
      "Epoch: 1/5 \t Time: 02:57:48.885937 \t Loss: 0.3331942874856293 \t Accuracy: 0.9209999999999999\n",
      "Epoch: 2/5 \t Time: 03:01:20.008677 \t Loss: 0.1535573620254174 \t Accuracy: 0.9470000000000002\n",
      "Epoch: 3/5 \t Time: 03:04:39.292673 \t Loss: 0.10320970850944869 \t Accuracy: 0.9590000000000001\n",
      "Epoch: 4/5 \t Time: 03:08:03.787511 \t Loss: 0.07606508990337607 \t Accuracy: 0.975\n",
      "Epoch: 5/5 \t Time: 03:11:21.162412 \t Loss: 0.0590286113537848 \t Accuracy: 0.985\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "from torchvision.models import resnet50\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import datetime\n",
    "from torch.nn import init, Linear, ReLU, Softmax\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "image_size = (224,224)\n",
    "transform=transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "train_data=dset.CIFAR10(root='./Dataset',train=True,transform=transform,download=False)\n",
    "test_data=dset.CIFAR10(root='./Dataset',train=False,transform=transform,download=False)\n",
    "train_loader=torch.utils.data.DataLoader(train_data,batch_size=20,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(test_data,batch_size=20,shuffle=True)\n",
    "train_len=len(train_data)\n",
    "test_len=len(test_data)\n",
    "print(train_len,test_len)\n",
    "\n",
    "rs50=resnet50(pretrained=True, progress = True) #这里采用resnet18模型\n",
    "\n",
    "#adjust resnet50 to my dataset\n",
    "class r50(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(r50,self).__init__()\n",
    "        self.rn50 = model\n",
    "        self.fl1 = nn.Linear(1000, 256)\n",
    "        self.fl2 = nn.Linear(256,10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.rn50(X)\n",
    "        X = F.relu(self.fl1(X))\n",
    "        X = F.dropout(X, p=0.25)\n",
    "        X = self.fl2(X)\n",
    "        return X\n",
    "def get_num_correct(out, labels):  #求准确率\n",
    "    return out.argmax(dim=1).eq(labels).sum().item()\n",
    "model = r50(rs50)\n",
    "criterion = nn.CrossEntropyLoss(reduction = \"mean\")\n",
    "optim = torch.optim.SGD(model.parameters(),lr=0.01)\n",
    "\n",
    "#put on cuda if possible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "nb_epochs = 5\n",
    "accuracy = []\n",
    "eps = 0.01\n",
    "eps_iter = 0.001\n",
    "steps = 20\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        model.eval()\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        prediction = model(images).to(torch.float32)\n",
    "        loss = criterion(prediction, labels.to(torch.long)) \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        #calculate accuracy\n",
    "        corrects = 0\n",
    "        pred = torch.argmax(prediction, dim = 1)\n",
    "        \n",
    "        for i, p,l in zip(range(64), pred, labels):\n",
    "            corrects += (p == l)\n",
    "        accuracy.append(int(corrects)/len(pred))\n",
    "    \n",
    "    print(\"Epoch: {j}/{total_epochs} \\t Time: {time} \\t Loss: {Loss} \\t Accuracy: {acc}\".format(j = epoch+1,Loss = running_loss/len(train_loader),total_epochs = nb_epochs,time = datetime.datetime.now().time(), acc=np.mean(accuracy[-50:])))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model for our test notebook    \n",
    "PATH = './cifar10_resnet50.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9566\n"
     ]
    }
   ],
   "source": [
    "model = r50(rs50)\n",
    "model.load_state_dict(torch.load('./cifar10_resnet50.pth'))\n",
    "correct_test = 0\n",
    "model.cuda(0)\n",
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        test_features, test_labels = data\n",
    "        outputs = model(test_features.cuda(0))\n",
    "        _,pred_idxs = torch.topk(outputs, 1)\n",
    "        correct_test += torch.eq(test_labels.cuda(0), pred_idxs.squeeze()).sum().item()\n",
    "print(correct_test/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n",
      "cuda:0\n",
      "Epoch: 1/3 \t Time: 03:21:09.588077 \t Loss: 0.3373229045111686 \t Accuracy: 0.9359999999999999\n",
      "Epoch: 2/3 \t Time: 03:26:21.064520 \t Loss: 0.13645767496023328 \t Accuracy: 0.961\n",
      "Epoch: 3/3 \t Time: 03:31:25.862904 \t Loss: 0.0878499648787547 \t Accuracy: 0.9739999999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "from torchvision.models import wide_resnet50_2\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import datetime\n",
    "from torch.nn import init, Linear, ReLU, Softmax\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "image_size = (224,224)\n",
    "transform=transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "train_data=dset.CIFAR10(root='./Dataset',train=True,transform=transform,download=False)\n",
    "test_data=dset.CIFAR10(root='./Dataset',train=False,transform=transform,download=False)\n",
    "train_loader=torch.utils.data.DataLoader(train_data,batch_size=20,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(test_data,batch_size=20,shuffle=True)\n",
    "train_len=len(train_data)\n",
    "test_len=len(test_data)\n",
    "print(train_len,test_len)\n",
    "\n",
    "wrs50=wide_resnet50_2(pretrained=True, progress = True) #这里采用resnet18模型\n",
    "\n",
    "#adjust resnet50 to my dataset\n",
    "class wr50(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(wr50,self).__init__()\n",
    "        self.wrn50 = model\n",
    "        self.fl1 = nn.Linear(1000, 256)\n",
    "        self.fl2 = nn.Linear(256,10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.wrn50(X)\n",
    "        X = F.relu(self.fl1(X))\n",
    "        X = F.dropout(X, p=0.25)\n",
    "        X = self.fl2(X)\n",
    "        return X\n",
    "def get_num_correct(out, labels):  #求准确率\n",
    "    return out.argmax(dim=1).eq(labels).sum().item()\n",
    "model = wr50(wrs50)\n",
    "criterion = nn.CrossEntropyLoss(reduction = \"mean\")\n",
    "optim = torch.optim.SGD(model.parameters(),lr=0.01)\n",
    "\n",
    "#put on cuda if possible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "nb_epochs = 3\n",
    "accuracy = []\n",
    "eps = 0.01\n",
    "eps_iter = 0.001\n",
    "steps = 20\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        model.eval()\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        prediction = model(images).to(torch.float32)\n",
    "        loss = criterion(prediction, labels.to(torch.long)) \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        #calculate accuracy\n",
    "        corrects = 0\n",
    "        pred = torch.argmax(prediction, dim = 1)\n",
    "        \n",
    "        for i, p,l in zip(range(64), pred, labels):\n",
    "            corrects += (p == l)\n",
    "        accuracy.append(int(corrects)/len(pred))\n",
    "    \n",
    "    print(\"Epoch: {j}/{total_epochs} \\t Time: {time} \\t Loss: {Loss} \\t Accuracy: {acc}\".format(j = epoch+1,Loss = running_loss/len(train_loader),total_epochs = nb_epochs,time = datetime.datetime.now().time(), acc=np.mean(accuracy[-50:])))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model for our test notebook    \n",
    "PATH = './cifar10_wideresnet50.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9639\n"
     ]
    }
   ],
   "source": [
    "model = wr50(wrs50)\n",
    "model.load_state_dict(torch.load('./cifar10_wideresnet50.pth'))\n",
    "correct_test = 0\n",
    "model.cuda(0)\n",
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        test_features, test_labels = data\n",
    "        outputs = model(test_features.cuda(0))\n",
    "        _,pred_idxs = torch.topk(outputs, 1)\n",
    "        correct_test += torch.eq(test_labels.cuda(0), pred_idxs.squeeze()).sum().item()\n",
    "print(correct_test/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
