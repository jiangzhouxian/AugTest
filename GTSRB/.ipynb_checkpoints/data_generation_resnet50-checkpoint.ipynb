{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/zx_pytorch/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/zx_pytorch/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Prepare all our necessary libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "#pytorch libraries\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Pad, Compose,CenterCrop, ToPILImage, Normalize, ConvertImageDtype, Resize,Compose\n",
    "\n",
    "from Models.resnet50 import *\n",
    "from Models.wide_resnet50 import *\n",
    "from Models.squeezenet import *\n",
    "from torchvision.models import resnet50,wide_resnet50_2,squeezenet1_0,vgg16\n",
    "\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import init, Linear, ReLU, Softmax\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.optim import SGD, Adam\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from img_utils import *\n",
    "from Aug_utils import *\n",
    "from Geometric_loss import *\n",
    "import datetime\n",
    "\n",
    "img_dir = \"./Models/Dataset/\"\n",
    "seed_file = \"./Models/Dataset/seed50.csv\"\n",
    "seed_data = GTSRB(img_dir = img_dir, annotations_file = seed_file,\n",
    "                   transform = Compose([Resize((30,30)), ConvertImageDtype(torch.float32)]))\n",
    "from torch.utils.data import DataLoader\n",
    "seed_dataloader = DataLoader(seed_data, batch_size=2, shuffle=False)\n",
    "test_features, test_labels = next(iter(seed_dataloader))\n",
    "\n",
    "\n",
    "pre_model = r50(resn50)\n",
    "pre_model.load_state_dict(torch.load('./Models/gtsrb_resnet50.pth'))\n",
    "print(\"model:resnet50\")\n",
    "pre_model_test1 = wr50(wresn50)\n",
    "pre_model_test1.load_state_dict(torch.load('./Models/gtsrb_wide_resnet50.pth'))\n",
    "pre_model_test2 = squeezenet(squ)\n",
    "pre_model_test2.load_state_dict(torch.load('./Models/gtsrb_squeezenet.pth'))\n",
    "feature_Extract_net =  vgg16(pretrained=True, progress = True)\n",
    "print(feature_Extract_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApBUlEQVR4nO3dbYxc5Xn/8d85Zx72wbtjFuNdb7x21iSBNgZXdbBrkbikXvmhEoLgF5DkhYkQCLqOCm6ayFECoa20FZEoSuTCmxa3UoAUKYCCVFdgYltp11R2QBZqa2HXqc3fXhMMO+N9mMdz/18AC4ttPNfx7N676+9HGsneuc6c+8y551w7O+f8JnDOOQEAMM1C3wMAAFyeaEAAAC9oQAAAL2hAAAAvaEAAAC9oQAAAL2hAAAAvaEAAAC9SvgfwSXEc6+TJk2pra1MQBL6HAwAwcs7p7Nmz6u7uVhhe+H3OjGtAJ0+eVE9Pj+9hAAAu0YkTJ7R48eIL3j/jGlBbW5sk6UurViqViupaJlGWUFDfY39sAVN1rVYzPr5k3ZIgsNWHgf0vrkE4tVMkyaPXxkdM9bm2ZlN9c1POVC9Jw+PjtvrC26b66FN+i7yQILA9u0Fkq4+itKlekmLjXzUC46cEcRyb6iXJOdsygfF1FCb4S04Q2paZ6ufVqlqt6sDg4MTx/EKm7OiyY8cO/fjHP9bQ0JBWrFihn/70p1q1atVFl/vwz26pVKRUqr7hzcQGlOzPhzSgegR1/mLyoXSd82iiPm0/sKYqFVN9FNm2IRUlaUC2dQTGMUXGhiXRgOpexyxvQBPruci4pmQUP//5z7Vt2zY99NBD+s1vfqMVK1Zow4YNevtt2299AIC5a0oa0KOPPqq7775b3/rWt/T7v//7euKJJ9TS0qJ//Md/nIrVAQBmoYY3oHK5rIMHD6qvr++jlYSh+vr6NDg4eE59qVRSoVCYdAMAzH0Nb0DvvPOOarWaOjs7J/28s7NTQ0ND59QPDAwol8tN3DgDDgAuD94vRN2+fbvy+fzE7cSJE76HBACYBg0/xWnBggWKokinT5+e9PPTp0+rq6vrnPpsNqtsNtvoYQAAZriGvwPKZDJauXKldu/ePfGzOI61e/durVmzptGrAwDMUlNykce2bdu0ZcsWfelLX9KqVav02GOPaXR0VN/61remYnUAgFloShrQ7bffrt/97nd68MEHNTQ0pD/4gz/Qrl27zjkx4dMMnTr1qRlCHxcluejTuEy5aks2iI0Xt0lSyni1e5IL3Kyc8Spf52xjsl6QKUmpyHbR53jJNs0zGVvSgiSNlcqm+mrNto4wtD9P6fQ8U/1o3nYGaqVi22ZJio3zwzqfrPP1/WXMk9xWnuTiWONF6c54cWxgvLBesl2wW+8FwYEzP/tTq1AoKJfL6bO9PTSgi6AB1Wdes7UBtZvqpTnSgMbGTPU0oDrLL9MGdOr/nVI+n1d7+4VfT97PggMAXJ5oQAAAL2hAAAAvaEAAAC9oQAAAL2hAAAAvaEAAAC9oQAAAL2hAAAAvaEAAAC9oQAAAL6YkjLQR4lqseuOQUil7Hw2NUUgpYxRXtWYPpQqN+U/2NKck2XG2ZULjE5uKkuT42XbGyJgts8yNvmuqTyJK2bY7CO0v1dgZswXDjKk+UYxkXDUuYMtgTDLDrXPWnKMW2Y9P5mfWuECQIEfSEm8Z1/nwvAMCAHhBAwIAeEEDAgB4QQMCAHhBAwIAeEEDAgB4QQMCAHhBAwIAeEEDAgB4QQMCAHhBAwIAeDFjs+BCFyusM98oSa5ROmXb9KDecKMPxLEhOOkDYWj9fcC63fbnKTbmfcU1Y9aXJWDqA+anyfh7lv3xpSgw5vhZs7tckpQzG2u2WzptP3xUqsYNN04P52zZcZIUGY8fzhi8Zp/hkjVmL7BOqAQCQ25jvcdk3gEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvJixWXBBSgrqbI9Ryt5Ho8i2jDUTLR1FpnpJqlnjnKx5UdYFJDljpp01A8+aPyZJoTPub+M6Uin7mKJ6gws/EBrnR4LpZN/fgTG1LKjY6iWFhjwxSQpC2yEqwXRSaIzZsx4LnPmFLVmjJK1xmGGS7DjDdtf7uuYdEADACxoQAMALGhAAwAsaEADACxoQAMALGhAAwAsaEADACxoQAMALGhAAwAsaEADACxoQAMALGhAAwIsZG0ZaUyCn+hL2yhV7KGKtUrUtYEz7SxD1p7jO7U26jsgYcCjZf0MJ6k2QnViB/Xegalwz1QfOtuFhNUFoa9q2HZl0xlQfpLOmekmqOVuCaWBMPK1WSqZ6SQqM+zs0hgYrTpDaagwXDY2vvFRkn09V4zpi4xy3BqpKtqcpjgkjBQDMYA1vQD/60Y8UBMGk27XXXtvo1QAAZrkp+RPcF7/4Rb388ssfrSQ1Y//SBwDwZEo6QyqVUldX11Q8NABgjpiSz4DefPNNdXd3a9myZfrmN7+p48ePX7C2VCqpUChMugEA5r6GN6DVq1dr586d2rVrlx5//HEdO3ZMX/nKV3T27Nnz1g8MDCiXy03cenp6Gj0kAMAMFLh6v7w7oeHhYS1dulSPPvqo7rrrrnPuL5VKKpU+Op2zUCiop6dHS3q7FdZ5ymYqwfebR8ZTnq2nYSc441lVZzwN21if5DRs6ymq5uk0A0/DTof2+ZQxnobd0tJsqg8ytnpJqjnbX9iL5aKpvlQcM9VL9tOwI+v8iBNM8ime40lOea7WpvY07CDBhSK207BjvXV8SPl8Xu3t7Resm/KzA+bPn68vfOELOnLkyHnvz2azymbt1zgAAGa3Kb8OaGRkREePHtWiRYumelUAgFmk4Q3oO9/5jvbu3avf/va3+o//+A997WtfUxRF+vrXv97oVQEAZrGG/wnurbfe0te//nWdOXNGV111lb785S9r//79uuqqqxq9KgDALNbwBvTMM8805HGiIFRYZ65YYDxB4P2FjONJ2d4sZlP2TKpy1fbheqlk++Axydkm1g9crfUJ9px5maa0bV80WfPHJKWN8yNt/OODtV6SqsZcPpdKm+pTLS2mekmqWU/PMZ5w4moJnifj665m/MA/icB4YlVofd0lOGZasgLjOk8GIQsOAOAFDQgA4AUNCADgBQ0IAOAFDQgA4AUNCADgBQ0IAOAFDQgA4AUNCADgBQ0IAOAFDQgA4MWUfx9QYs7V/w1ICXKNasbspEqpaluBtV5SbEw5c7Ex/ylBGJz1qY2MCyT4Pjqls62m+qzxeQ2rpYsXfUJkzSAzfnFatThie3xJgfF7tlLGDLwoQWaei2xjKhVt+6JaGzfVv29qc9SqSb4kz8i67xJ9Dalhu4M6X3O8AwIAeEEDAgB4QQMCAHhBAwIAeEEDAgB4QQMCAHhBAwIAeEEDAgB4QQMCAHhBAwIAeEEDAgB4QQMCAHgxY8NIXa0mV2diXmzPIlVgTMG0ZvclyfqTNbPQuJIk4ZHWcNG0cVBN6chUL0kp43a7UtlUH9QqthVIcsbAyZqz7YsgwYxyo2O2+si2r4Ns2lQvSS3tOds6Itv8qBiDZyXJuNkKraHBCZI/Y2ebT0FofR3ZA1Itc9DVWcs7IACAFzQgAIAXNCAAgBc0IACAFzQgAIAXNCAAgBc0IACAFzQgAIAXNCAAgBc0IACAFzQgAIAXMzYLLkqFiurNazPmuklSaMxFc65qqq/V7PlP1ny6wBjnZM28kqQm40LNKVs+WFCzPa+SVC2OmOojY3ZXJpsx1UtSpqnVtkCQtZUn2HeuVjTVj44UTPWlsZKpXpJGK78z1Wfabc9re0uLqV6SShXba7VctWYFJjgWGJex5s0FCSZUbFgHWXAAgBmNBgQA8IIGBADwggYEAPCCBgQA8IIGBADwggYEAPCCBgQA8IIGBADwggYEAPCCBgQA8GLGZsE5hXL19kdnzzUKjL03MOaJ1RJknAWBMc/JmP8UhvbnqTmyZbuljDlZxeKoqV6SmlvabPXzcqb6dII8sdQ825hiYxacPU1MSjnbvgjOnDHVh4WzpnpJqo7nTfWlgq2+uX2BqV6S4qYmU/3oWM32+Al+zQ9i42vVOEEiY2ajJFWr9R/T4jqPl7wDAgB4QQMCAHhhbkD79u3TzTffrO7ubgVBoOeff37S/c45Pfjgg1q0aJGam5vV19enN998s1HjBQDMEeYGNDo6qhUrVmjHjh3nvf+RRx7RT37yEz3xxBN69dVX1draqg0bNqhYtH03CQBgbjOfhLBp0yZt2rTpvPc55/TYY4/pBz/4gW655RZJ0j//8z+rs7NTzz//vO64445LGy0AYM5o6GdAx44d09DQkPr6+iZ+lsvltHr1ag0ODp53mVKppEKhMOkGAJj7GtqAhoaGJEmdnZ2Tft7Z2Tlx3ycNDAwol8tN3Hp6eho5JADADOX9LLjt27crn89P3E6cOOF7SACAadDQBtTV1SVJOn369KSfnz59euK+T8pms2pvb590AwDMfQ1tQL29verq6tLu3bsnflYoFPTqq69qzZo1jVwVAGCWM58FNzIyoiNHjkz8/9ixY3r99dfV0dGhJUuW6P7779ff/M3f6POf/7x6e3v1wx/+UN3d3br11lsbOW4AwCxnbkAHDhzQV7/61Yn/b9u2TZK0ZcsW7dy5U9/97nc1Ojqqe+65R8PDw/ryl7+sXbt2qcmYtwQAmNsC54yJllOsUCgol8upt3eJwrC+vxAGgT1TNTL+8bFcLZvqazVbYKEkBcb8waxxG+Y3t9oWkBTY8iwVF22n0Te3ZWwrkHRl5xJTfdhkCwpVxj6fasad5wLjzrNODkmh8aUdGFMzi3n7xeWl/PnPhr2QwrunbCtIcjhrs82Pasr4PJVsxw5JqlZt2+FiW32Uikz1klQxHNPiONZv//eE8vn8p36u7/0sOADA5YkGBADwggYEAPCCBgQA8IIGBADwggYEAPCCBgQA8IIGBADwggYEAPCCBgQA8IIGBADwwh56NV2CoO78K+eqCVZg673ptO2pCiN71lIYx6b6psiWD5Y25kVJUrlUMtVn0y2m+rbcVaZ6SXJpW7CtM2a7xaE9d03WRZxtXztnH1PVOCgX2uZHyxXNpnpJUjVnW8eIMYNxfNhU//4ytjkeZmzzL46ypnpJCgLbMc2aPZkkMs8yZeut5R0QAMALGhAAwAsaEADACxoQAMALGhAAwAsaEADACxoQAMALGhAAwAsaEADACxoQAMALGhAAwIsZmwUXyClQvYFFthwkyZ6dFBtzteIEuWthaPt9IJWy7T6XYExOtsyybJMtCy6VtWWDSfYsLletmOoTJMFJkfF3OeO+riQI74qNL4vAmE9XdPbXXXP7FaZ6V7JlKg4XR031khQbd3imqc1UX6za8uwkqRYXbQsYt6FWs8+nSq3++RHXmWvJOyAAgBc0IACAFzQgAIAXNCAAgBc0IACAFzQgAIAXNCAAgBc0IACAFzQgAIAXNCAAgBc0IACAFzQgAIAXMzaM1MU1uTrDSF2CoMb6g04/qDeGRwZJIi2Nm5EKbUGNgTGUU7JvR1Nrq6k+lU6b6iVpfMwY1FixhUEGso+pbPxdLtWaNdWPVKqmekkaHSmZ6lvStvlULRv3g6SmrG1f5Fpt8y9M21935artuU3FtteRNaf2fbaFwsBWH0X2Y2YmqL9dxHUGl/IOCADgBQ0IAOAFDQgA4AUNCADgBQ0IAOAFDQgA4AUNCADgBQ0IAOAFDQgA4AUNCADgBQ0IAODFjM2CS4eRojpDlKoJsuAqNVv+U1hnttGH0sZsJknKGLPdrIllgXGbJSmwRmtlMqby4XfeMa5AknU7rBl4gW0bJKmYti0TqWaqf8+afyepMDxiqm9N2Q4H5aota06SWttsz1O2xTbLg8ieBRfUjLmQsW3fBeYXkRQ42zLWbMtUaB9TyjDHa7X6niPeAQEAvDA3oH379unmm29Wd3e3giDQ888/P+n+O++8U0EQTLpt3LixUeMFAMwR5gY0OjqqFStWaMeOHRes2bhxo06dOjVxe/rppy9pkACAucf8GdCmTZu0adOmT63JZrPq6upKPCgAwNw3JZ8B7dmzRwsXLtQ111yj++67T2fOnJmK1QAAZrGGnwW3ceNG3Xbbbert7dXRo0f1/e9/X5s2bdLg4KCi6NyzvEqlkkqlj86mKRQKjR4SAGAGangDuuOOOyb+fd111+n666/X1VdfrT179mjdunXn1A8MDOjhhx9u9DAAADPclJ+GvWzZMi1YsEBHjhw57/3bt29XPp+fuJ04cWKqhwQAmAGm/ELUt956S2fOnNGiRYvOe382m1U2m53qYQAAZhhzAxoZGZn0bubYsWN6/fXX1dHRoY6ODj388MPavHmzurq6dPToUX33u9/V5z73OW3YsKGhAwcAzG7mBnTgwAF99atfnfj/tm3bJElbtmzR448/rkOHDumf/umfNDw8rO7ubq1fv15//dd/zbscAMAk5gZ00003yX1K9tq//du/XdKAPpRJh3VnwcV15g59XBgbP/5ytiy4KJUga8m4jDE6TjLmRUn2jClzFFeCnKyyMYvrPCdffqogLNsWkBREtufJOeNLr2bPgsumbM9TaHxJpFP2j5DLJVt+nGu2Jh5OvdiY0+aUIAvO+LpwxteES5JPZ3hduDqPl2TBAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvJjy7wNKKo6dgqC+gMcwQdifdRFreJ8LE4zJGu5oXEdoTgqVopotZLNWtIVmtrTlTPWS1JS9wlSfTtvSSCsVe/BntVo11UfpjKneug2SlOlcYKqPjKmtcWyfT4VC3lSfNr7uahXbfpAkY7aoqrIFE5er9rBkZ1yH6jxWfvT4dtVype7auEYYKQBgBqMBAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8mLFZcLVaTfUmFtWcPdkoNGZMBcZW7WJ7/pM1MqpizHazZn1JUlW2QRXHRk3181rbTPWS1NraYqqvGXO1wkyC3DXrHDRmd2Vbm2yPn4htkofGuDJJmpe60lT/7omTpvpqgiy4uCVtqq8YXxNj5XFTvSQFxjmbtr62ExwzI1OAZn21vAMCAHhBAwIAeEEDAgB4QQMCAHhBAwIAeEEDAgB4QQMCAHhBAwIAeEEDAgB4QQMCAHhBAwIAeDFjs+CqcVxnEpxUf+VHwtCWnRRGtl4dJBiTnC3bLTYG1DW1tprqJalatWVSlUsjpvpaedhUL0nVcdu0jZrnmeqtz6skxcbsLnOMWoLpVG8e10frMM7xiu3hJSl/2pbtNlZ4x1QfRfZD2rgypvqxki1vLk6w76wzsFK1jSkK7M9TypSfSRYcAGAGowEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvJixYaRKZaR6A0CdOdoxQRikbYm0MbxUktLp9JTWR2lb6KIktebaTfXF4XdN9fn3hkz1khSlbNsRGn/PSmVsQbWS5CLbMrGzJVQGpiDI90XGEMy4WDLV539XsK1AUrnwnqk+rhVN9UHUZKqXpMAY2urimqk+DO37LjDOWVezHZ9qxvknSWGq/u2ICSMFAMxkpgY0MDCgG264QW1tbVq4cKFuvfVWHT58eFJNsVhUf3+/rrzySs2bN0+bN2/W6dOnGzpoAMDsZ2pAe/fuVX9/v/bv36+XXnpJlUpF69ev1+jo6ETNAw88oF/+8pd69tlntXfvXp08eVK33XZbwwcOAJjdTJ8B7dq1a9L/d+7cqYULF+rgwYNau3at8vm8/uEf/kFPPfWU/uRP/kSS9OSTT+r3fu/3tH//fv3RH/1R40YOAJjVLukzoHw+L0nq6OiQJB08eFCVSkV9fX0TNddee62WLFmiwcHB8z5GqVRSoVCYdAMAzH2JG1Acx7r//vt14403avny5ZKkoaEhZTIZzZ8/f1JtZ2enhobOf7bTwMCAcrncxK2npyfpkAAAs0jiBtTf36833nhDzzzzzCUNYPv27crn8xO3EydOXNLjAQBmh0TXAW3dulUvvvii9u3bp8WLF0/8vKurS+VyWcPDw5PeBZ0+fVpdXV3nfaxsNqtsNptkGACAWcz0Dsg5p61bt+q5557TK6+8ot7e3kn3r1y5Uul0Wrt375742eHDh3X8+HGtWbOmMSMGAMwJpndA/f39euqpp/TCCy+ora1t4nOdXC6n5uZm5XI53XXXXdq2bZs6OjrU3t6ub3/721qzZg1nwAEAJjE1oMcff1ySdNNNN036+ZNPPqk777xTkvR3f/d3CsNQmzdvVqlU0oYNG/T3f//3DRksAGDuCJxLEAo0hQqFgnK5nD7bu1hhWN9fCINpCBSypoNl0vZBRcY8sYwxCy4M7R/5ZYyzI10pm+qL4yO2FUgKA9t2NzW1mupTTbbHl6SodZ6pPg6MMyrBqzQuV0z1Y/lhU315dNxUL0mBMUetFhlz2jL2vMORqu15KtVsczyVss8nZ82Cs4ZbJjjsW/II4zjW/x47rnw+r/b2C+dJkgUHAPCCBgQA8IIGBADwggYEAPCCBgQA8IIGBADwggYEAPCCBgQA8IIGBADwggYEAPCCBgQA8CLR9wFNi7imegOwwiR91BYxpSC0LRAnye6q2XKyqsZ1xK5qW0BS1riO+SlbxlmrMUNNkoqjtuepmLdllkWFvKleklz4jm0BY55dksTGuGbb3zXjpA2M2yBJMs6PWrNtHe+VbTltklQrl0z16ZTteGM8dEiSajVjuJuzraQWW8PjVHc2pyTFdU5Y3gEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8mLFhpNVaTWGdgXYJchpNwXqSFBjTIOMEaaTmJYyBhUFoC4KUpJIxtPAdY7Bjc8Y+BdvaF5nqx4dtY8qkR0z1klSqjZnqi8WKqT5IEB4ZRLaAyrCpzVRfrGVN9ZIUZGxhocXqqKm+WkkSsmmcg4E1+HPqjwWB8a1EaE1jVv0Bo5Za3gEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvJixWXCKIqnOvDaXIOMsNqYtBcZwJpcg/yk2533Z6jNp++8bLrA9t2OBbUyj47ZsMEk6W37HVN+WbrGtoLnZVi+ptXm+rd74u9/Z99411UtSOa6Z6seN8WDl0Pb4klSq2vZ35GzrmNdkz6crlqqm+ti474wxkokWsmZVplL2Q78zZE8GdWbN8Q4IAOAFDQgA4AUNCADgBQ0IAOAFDQgA4AUNCADgBQ0IAOAFDQgA4AUNCADgBQ0IAOAFDQgA4MWMzYLLhKHCerPgEmQtWRdxgTEoyxnrJTljFFwQGvOi6nw+Py6MbNlamXTGVB8Y88okey5fUSVTfblk33eVom0dMub+hdbJISmIbDl+Udp2OGi2viYkNQW2nL1ITbYVJDkYBBVTecU4ZauGDLUPOWcbkzUXMo5t+XeSFAT1Hz/qnRq8AwIAeEEDAgB4YWpAAwMDuuGGG9TW1qaFCxfq1ltv1eHDhyfV3HTTTQqCYNLt3nvvbeigAQCzn6kB7d27V/39/dq/f79eeuklVSoVrV+/XqOjo5Pq7r77bp06dWri9sgjjzR00ACA2c/0qeOuXbsm/X/nzp1auHChDh48qLVr1078vKWlRV1dXY0ZIQBgTrqkz4Dy+bwkqaOjY9LPf/azn2nBggVavny5tm/frrGxsQs+RqlUUqFQmHQDAMx9iU/DjuNY999/v2688UYtX7584uff+MY3tHTpUnV3d+vQoUP63ve+p8OHD+sXv/jFeR9nYGBADz/8cNJhAABmqcC5RN9Yrvvuu0//+q//ql//+tdavHjxBeteeeUVrVu3TkeOHNHVV199zv2lUkml0kfXUBQKBfX09GhZ72cM1wEluObGeCVQENrWUe93on9cXLNdYGA4LV+SlM3arsGQpMB4HVDN+rxOw3VAkXFfhAn2XcX6MpqW64BsEyQ0XgdU98UeH+OMOy+yXrGX4HBWLM/A64Bi25gC43VAkXFuSJIz/MEsjmP99n9PKJ/Pq729/YJ1id4Bbd26VS+++KL27dv3qc1HklavXi1JF2xA2WxW2aztIAcAmP1MDcg5p29/+9t67rnntGfPHvX29l50mddff12StGjRokQDBADMTaYG1N/fr6eeekovvPCC2traNDQ0JEnK5XJqbm7W0aNH9dRTT+lP//RPdeWVV+rQoUN64IEHtHbtWl1//fVTsgEAgNnJ1IAef/xxSe9fbPpxTz75pO68805lMhm9/PLLeuyxxzQ6Oqqenh5t3rxZP/jBDxo2YADA3GD+E9yn6enp0d69ey9pQB+KqzWpzrDNOMGHxtaPKgPjiQ5Bgg9oA+OowsAWNtmU4CSEbMsVpvooYxuTXNlWL/vnzNaTFuIEp+WUjSeQyNnqUwlOQrCKjVM2yTUcoXkpW70zPq+SlG6yPbdV44kzY+PjpnpJGh+zhYVaT8QyngPzwTrq3+64zhWQBQcA8IIGBADwggYEAPCCBgQA8IIGBADwggYEAPCCBgQA8IIGBADwggYEAPCCBgQA8IIGBADwIvE3ok41S1RRvblDH2f9gjn792LZA8Ws+XGRsX5etslUL0m53IW/TOp8ouaMqd7JlnklSTVrWJvxC8HKFfuY3iva8r5GzuZN9aly6eJFn+CsX8TX2mJbQXHMVi+pM9dhqm9tn2+qjxNkMJZrtv397vB7pvraqD0LzjrH64zNnOASvPUIwvpzHuv9Qk7eAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8oAEBALygAQEAvKABAQC8mLFZcEEQ1J2NZogomvT4xiVM1fYkuGTLWIRBzbxMOm3LUXOmFD+pluB3oFK1Yqovjtgyy0bHRk31kvS7wrBtHSNnTfXpBPl0NeOEqhhfR7m0fcbOM87yebk2U30QpU317y9kOwzWAts6Ymc/QAWB7XURx7b5ESQ42ISGMdV7eOUdEADACxoQAMALGhAAwAsaEADACxoQAMALGhAAwAsaEADACxoQAMALGhAAwAsaEADACxoQAMALGhAAwIsZG0Yam0ItrcGiknO2ZazhpS5B2F8ga1iocSUJEgitS9j2mxQn2HfvFvKm+rP5YVN9XLNtgySpZtt3gbG+ZqyXpNj4+2U6nTHVl4tFU70kpUPbOsyhnOaQYalinOVV4/MaJzkWWI83CV5HZrHhdVFnLe+AAABe0IAAAF7QgAAAXtCAAABe0IAAAF7QgAAAXtCAAABe0IAAAF7QgAAAXtCAAABezLgoHvdBhk1siX2YhhiK6YjikTHGplazjalatce5VCoVU31s3PBqgn1Xq1Zt9cYYG5cgisca32Ob31JgrJcSxCgZ12Gtl6SqcV9Y518lQe5N1bjvrPMvThKjNMX7IskRMzAs9eF43EWOB4G7WMU0e+utt9TT0+N7GACAS3TixAktXrz4gvfPuAYUx7FOnjyptra2c951FAoF9fT06MSJE2pvb/c0wul1OW6zdHlu9+W4zRLbPRe32zmns2fPqru7W2F44U96Ztyf4MIw/NSOKUnt7e1zboddzOW4zdLlud2X4zZLbPdck8vlLlrDSQgAAC9oQAAAL2ZVA8pms3rooYeUzWZ9D2XaXI7bLF2e2305brPEdl9u2/1xM+4kBADA5WFWvQMCAMwdNCAAgBc0IACAFzQgAIAXs6YB7dixQ5/97GfV1NSk1atX6z//8z99D2lK/ehHP1IQBJNu1157re9hNdS+fft08803q7u7W0EQ6Pnnn590v3NODz74oBYtWqTm5mb19fXpzTff9DPYBrrYdt95553n7PuNGzf6GWyDDAwM6IYbblBbW5sWLlyoW2+9VYcPH55UUywW1d/fryuvvFLz5s3T5s2bdfr0aU8jbox6tvumm246Z3/fe++9nkY8vWZFA/r5z3+ubdu26aGHHtJvfvMbrVixQhs2bNDbb7/te2hT6otf/KJOnTo1cfv1r3/te0gNNTo6qhUrVmjHjh3nvf+RRx7RT37yEz3xxBN69dVX1draqg0bNqhYLE7zSBvrYtstSRs3bpy0759++ulpHGHj7d27V/39/dq/f79eeuklVSoVrV+/XqOjoxM1DzzwgH75y1/q2Wef1d69e3Xy5EnddtttHkd96erZbkm6++67J+3vRx55xNOIp5mbBVatWuX6+/sn/l+r1Vx3d7cbGBjwOKqp9dBDD7kVK1b4Hsa0keSee+65if/Hcey6urrcj3/844mfDQ8Pu2w2655++mkPI5wan9xu55zbsmWLu+WWW7yMZ7q8/fbbTpLbu3evc+79fZtOp92zzz47UfPf//3fTpIbHBz0NcyG++R2O+fcH//xH7s///M/9zcoj2b8O6ByuayDBw+qr69v4mdhGKqvr0+Dg4MeRzb13nzzTXV3d2vZsmX65je/qePHj/se0rQ5duyYhoaGJu33XC6n1atXz/n9Lkl79uzRwoULdc011+i+++7TmTNnfA+pofL5vCSpo6NDknTw4EFVKpVJ+/vaa6/VkiVL5tT+/uR2f+hnP/uZFixYoOXLl2v79u0aGxvzMbxpN+PCSD/pnXfeUa1WU2dn56Sfd3Z26n/+5388jWrqrV69Wjt37tQ111yjU6dO6eGHH9ZXvvIVvfHGG2pra/M9vCk3NDQkSefd7x/eN1dt3LhRt912m3p7e3X06FF9//vf16ZNmzQ4OKgoinwP75LFcaz7779fN954o5YvXy7p/f2dyWQ0f/78SbVzaX+fb7sl6Rvf+IaWLl2q7u5uHTp0SN/73vd0+PBh/eIXv/A42ukx4xvQ5WrTpk0T/77++uu1evVqLV26VP/yL/+iu+66y+PIMNXuuOOOiX9fd911uv7663X11Vdrz549WrdunceRNUZ/f7/eeOONOfeZ5sVcaLvvueeeiX9fd911WrRokdatW6ejR4/q6quvnu5hTqsZ/ye4BQsWKIqic86GOX36tLq6ujyNavrNnz9fX/jCF3TkyBHfQ5kWH+7by32/S9KyZcu0YMGCObHvt27dqhdffFG/+tWvJn3tSldXl8rlsoaHhyfVz5X9faHtPp/Vq1dL0pzY3xcz4xtQJpPRypUrtXv37omfxXGs3bt3a82aNR5HNr1GRkZ09OhRLVq0yPdQpkVvb6+6urom7fdCoaBXX331strv0vvfEnzmzJlZve+dc9q6dauee+45vfLKK+rt7Z10/8qVK5VOpyft78OHD+v48eOzen9fbLvP5/XXX5ekWb2/6+b7LIh6PPPMMy6bzbqdO3e6//qv/3L33HOPmz9/vhsaGvI9tCnzF3/xF27Pnj3u2LFj7t///d9dX1+fW7BggXv77bd9D61hzp4961577TX32muvOUnu0Ucfda+99pr7v//7P+ecc3/7t3/r5s+f71544QV36NAhd8stt7je3l43Pj7ueeSX5tO2++zZs+473/mOGxwcdMeOHXMvv/yy+8M//EP3+c9/3hWLRd9DT+y+++5zuVzO7dmzx506dWriNjY2NlFz7733uiVLlrhXXnnFHThwwK1Zs8atWbPG46gv3cW2+8iRI+6v/uqv3IEDB9yxY8fcCy+84JYtW+bWrl3reeTTY1Y0IOec++lPf+qWLFniMpmMW7Vqldu/f7/vIU2p22+/3S1atMhlMhn3mc98xt1+++3uyJEjvofVUL/61a+cpHNuW7Zscc69fyr2D3/4Q9fZ2emy2axbt26dO3z4sN9BN8CnbffY2Jhbv369u+qqq1w6nXZLly51d99996z/Zet82yvJPfnkkxM14+Pj7s/+7M/cFVdc4VpaWtzXvvY1d+rUKX+DboCLbffx48fd2rVrXUdHh8tms+5zn/uc+8u//EuXz+f9Dnya8HUMAAAvZvxnQACAuYkGBADwggYEAPCCBgQA8IIGBADwggYEAPCCBgQA8IIGBADwggYEAPCCBgQA8IIGBADwggYEAPDi/wPd70z8cZ+LwwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label= tensor(9)\n",
      "pred= tensor([[9]])\n"
     ]
    }
   ],
   "source": [
    "img = test_features[0]\n",
    "label = test_labels[0]\n",
    "imshow(img)\n",
    "print('label=',label)\n",
    "\n",
    "#pre_model.cuda()\n",
    "pre_model.eval() \n",
    "with torch.no_grad():\n",
    "    img = img.reshape(1,3,30,30)\n",
    "    outputs = pre_model(img)\n",
    "    _,pred = torch.topk(outputs, 1)\n",
    "print('pred=',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = 'ResNet50'\n",
    "save_dir = './generated_inputs/' + subdir + '/'\n",
    "orig_dir = './generated_inputs/' + subdir + '/seeds/'\n",
    "if os.path.exists(save_dir):\n",
    "    for i in os.listdir(save_dir):\n",
    "        path_file = os.path.join(save_dir, i)\n",
    "        if os.path.isfile(path_file):\n",
    "            os.remove(path_file)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "if os.path.exists(orig_dir):\n",
    "    for i in os.listdir(orig_dir):\n",
    "        path_file = os.path.join(orig_dir, i)\n",
    "        if os.path.isfile(path_file):\n",
    "            os.remove(path_file)\n",
    "\n",
    "if not os.path.exists(orig_dir):\n",
    "    os.makedirs(orig_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_adv= 182\n",
      "ave_diver =  inf\n",
      "error_1,error_2= 131 120\n",
      "error_rate= 0.7197802197802198 0.6593406593406593\n",
      "ave_search_time= 6.543956043956044\n",
      "Total time= 94.760428\n",
      "ave_time= 0.5206616923076923\n"
     ]
    }
   ],
   "source": [
    "step = 0.5\n",
    "T = 3\n",
    "max_search = 3\n",
    "num_adv = 0\n",
    "ave_diver = 0\n",
    "ave_search_time = []\n",
    "start_time = datetime.datetime.now()\n",
    "test_error1 = 0\n",
    "test_error2 = 0\n",
    "\n",
    "for i, data in enumerate(seed_dataloader, 0):\n",
    "    img, label = data\n",
    "    #原始图片和标签\n",
    "    orig_img = img\n",
    "    orig_label = label\n",
    "    #imshow(img[0])\n",
    "    #imshow(img[1])\n",
    "    #初始化参数\n",
    "    search_times = 0\n",
    "    for search in range(max_search):\n",
    "        search_times += 1\n",
    "        \n",
    "        theta = np.random.randint(-30,30)\n",
    "        tx = np.random.uniform(-0.1,0.1)\n",
    "        sx = np.random.uniform(-0.1,0.1)\n",
    "        zx = np.random.uniform(0.8,1.2)\n",
    "        beta = np.random.uniform(-32,32)\n",
    "        alpha = np.random.uniform(0.8,1.2)\n",
    "        #print(theta,tx,sx,zx,beta,alpha)\n",
    "        #初始化模型\n",
    "        modelA = nn.Sequential(rotation_layer(theta),\n",
    "                               translate_layer(tx),\n",
    "                               shear_layer(sx),\n",
    "                               zoom_layer(zx),\n",
    "                               brightness_layer(beta),\n",
    "                               contrast_layer(alpha))\n",
    "        modelB = pre_model\n",
    "        \n",
    "        m = feature_Extract_net.features[28]\n",
    "        inter_feature = {}\n",
    "        def hook(m, input, output):\n",
    "            inter_feature['features[28]'] = output\n",
    "    \n",
    "        m.register_forward_hook(hook)\n",
    "        #损失函数\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        geo = GeometricLoss()\n",
    "        for iterate in range(T): \n",
    "            search_times+=1\n",
    "            \n",
    "            x = modelA(img)\n",
    "            predictions = modelB(x)\n",
    "            loss = criterion(predictions, label)\n",
    "            loss.backward()\n",
    "           \n",
    "            #提取VGG16最后一个卷积层的特征向量 shape=（512，14，14）\n",
    "            transform = Resize((224,224))\n",
    "            resized_img = transform(img)\n",
    "            #print(resized_img.shape)\n",
    "            x_fea = modelA(resized_img)\n",
    "            #print(x_fea.shape)\n",
    "            fea = feature_Extract_net(x_fea)\n",
    "            feat = inter_feature['features[28]'] \n",
    "            \n",
    "            #多样性分数\n",
    "            diversity = geo(feat)\n",
    "            diversity = diversity.detach().numpy()\n",
    "\n",
    "            grads = []\n",
    "            for tt in modelA.parameters():\n",
    "                #print(tt)\n",
    "                g = tt.grad\n",
    "                g = g.numpy()\n",
    "                grads.append(g[0])\n",
    "            grads = np.array(grads)\n",
    "            #print(grads)\n",
    "            #梯度上升更新参数\n",
    "            theta += step* np.sign(grads[0])\n",
    "            tx += step* np.sign(grads[1])\n",
    "            sx += step* np.sign(grads[2])\n",
    "            zx += step* np.sign(grads[3])\n",
    "            beta += step* np.sign(grads[4])\n",
    "            alpha += step* np.sign(grads[5])\n",
    "\n",
    "            theta = np.clip(theta,-30,30)\n",
    "            tx = np.clip(tx,-0.1,0.1)\n",
    "            sx = np.clip(sx,-0.1,0.1)\n",
    "            zx = np.clip(zx,0.8,1.2)\n",
    "            beta = np.clip(beta,-32,32)\n",
    "            alpha = np.clip(alpha,0.8,1.2)\n",
    "            #print(theta,tx,sx,zx,beta,alpha)\n",
    "\n",
    "            modelA = nn.Sequential(rotation_layer(theta),\n",
    "                                   translate_layer(tx),\n",
    "                                   shear_layer(sx),\n",
    "                                   zoom_layer(zx),\n",
    "                                   brightness_layer(beta),\n",
    "                                   contrast_layer(alpha))\n",
    "\n",
    "            gen_img = modelA(orig_img)\n",
    "            modelB.eval()\n",
    "\n",
    "            outputs_1 = modelB(gen_img[0].reshape(1,3,30,30))\n",
    "            outputs_2 = modelB(gen_img[1].reshape(1,3,30,30))\n",
    "            _,pred_label_1 = torch.topk(outputs_1, 1)\n",
    "            _,pred_label_2 = torch.topk(outputs_2, 1)\n",
    "            if pred_label_1[0][0]!= orig_label[0]:\n",
    "                #print('Is adv!')\n",
    "                ave_search_time.append(search_times)\n",
    "                num_adv+=1\n",
    "                print(diversity)\n",
    "                ave_diver += diversity\n",
    "                #对抗样本迁移性测试\n",
    "                pre_model_test1.eval()\n",
    "                pre_model_test2.eval()\n",
    "                \n",
    "                test1 = pre_model_test1(gen_img[0].reshape(1,3,30,30))\n",
    "                _,test1_pre = torch.topk(test1, 1)\n",
    "                test_la1 = test1_pre[0][0]\n",
    "                \n",
    "                test2 = pre_model_test2(gen_img[0].reshape(1,3,30,30))\n",
    "                _,test2_pre = torch.topk(test2, 1)\n",
    "                test_la2 = test2_pre[0][0]\n",
    "                \n",
    "                if test_la1 != orig_label[0]:\n",
    "                    test_error1 +=1\n",
    "                if test_la2 != orig_label[0]:\n",
    "                    test_error2 +=1              \n",
    "                #保存对抗样本\n",
    "                adv_img = gen_img[0]\n",
    "                adv_label = pred_label_1\n",
    "                adv_img = adv_img.squeeze(0)\n",
    "                orig_ = orig_img[0]\n",
    "                orig_ = orig_.squeeze(0)\n",
    "                adv_img_save = transforms.ToPILImage()(adv_img)\n",
    "                orig_img_save = transforms.ToPILImage()(orig_)\n",
    "                adv_img_save.save('{}adv_{}_{}_{}.jpg'.format(save_dir,str(num_adv),str(orig_label[1].numpy()),str(pred_label_1[0][0].numpy())))\n",
    "                orig_img_save.save('{}orig_{}_{}.jpg'.format(orig_dir,str(num_adv),str(orig_label[1].numpy())))\n",
    "            if pred_label_2[0][0]!= orig_label[1]:\n",
    "                ave_search_time.append(search_times)\n",
    "                #print('Is adv!')\n",
    "                num_adv+=1\n",
    "                ave_diver += diversity\n",
    "                print(diversity)\n",
    "                #对抗样本迁移性测试\n",
    "                pre_model_test1.eval()\n",
    "                pre_model_test2.eval()\n",
    "                \n",
    "                test1 = pre_model_test1(gen_img[1].reshape(1,3,30,30))\n",
    "                _,test1_pre = torch.topk(test1, 1)\n",
    "                test_la1 = test1_pre[0][0]\n",
    "                \n",
    "                test2 = pre_model_test2(gen_img[1].reshape(1,3,30,30))\n",
    "                _,test2_pre = torch.topk(test2, 1)\n",
    "                test_la2 = test2_pre[0][0]\n",
    "                \n",
    "                if test_la1 != orig_label[1]:\n",
    "                    test_error1 +=1\n",
    "                if test_la2 != orig_label[1]:\n",
    "                    test_error2 +=1 \n",
    "                #保存对抗样本\n",
    "                adv_img = gen_img[1]\n",
    "                adv_label = pred_label_2\n",
    "                adv_img = adv_img.squeeze(0)\n",
    "                orig_ = orig_img[1]\n",
    "                orig_ = orig_.squeeze(0)\n",
    "                adv_img_save = transforms.ToPILImage()(adv_img)\n",
    "                orig_img_save = transforms.ToPILImage()(orig_)\n",
    "                adv_img_save.save('{}adv_{}_{}_{}.jpg'.format(save_dir,str(num_adv),str(orig_label[1].numpy()),str(pred_label_2[0][0].numpy())))\n",
    "                orig_img_save.save('{}orig_{}_{}.jpg'.format(orig_dir,str(num_adv),str(orig_label[1].numpy())))\n",
    "\n",
    "            img = gen_img\n",
    "        \n",
    "duration = (datetime.datetime.now() - start_time).total_seconds()       \n",
    "print('num_adv=',num_adv)\n",
    "print('ave_diver = ',ave_diver/num_adv)\n",
    "print('error_1,error_2=',test_error1,test_error2)\n",
    "print('error_rate=',test_error1/num_adv,test_error2/num_adv)\n",
    "ave_search_time = np.array(ave_search_time)\n",
    "print('ave_search_time=',np.sum(ave_search_time)/num_adv)\n",
    "print('Total time=',duration)\n",
    "print('ave_time=',duration/num_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zx_pytorch",
   "language": "python",
   "name": "zx_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
